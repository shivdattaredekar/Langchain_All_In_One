{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. Create a simple LLM model using OPENAI API\n",
    "2. Create a simple LLM model using Hugging Face API\n",
    "3. Use of prompts to create a simple LLM model and create a chaining model\n",
    "4. Use Simple sequential chains to create a simple LLM model\n",
    "5. Use of Sequential chains to create a simple LLM model\n",
    "6. Create simple ChatModels\n",
    "7. Use of output parsers to customised our outputs in Chat models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from langchain.llms import OpenAI\n",
    "from constants import openai_key # you will have to make one API key on OPENAI first and then use here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPEN_API_KEY\"] = openai_key\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = 'hf_bdssjzxxxxxxxxxevsrWshivaSLNNgVaZNLk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temperature value = How creative we want our model to be \n",
    "    1. If the value is more towords 0 it means model will not take any bets it will play safe \n",
    "    2. If value is more towords 1 it means model may generate wrong output but it wll be creative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nThe name of Mukesh Ambani's son is Akash Ambani.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=OpenAI(temperature = 0.8,api_key=openai_key)\n",
    "llm.invoke('whats is the name of mukesh ambani son?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOw lets try with hugging face\n",
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface = HuggingFaceHub(repo_id = \"google/flan-t5-large\",\n",
    "               model_kwargs={'temperature':0, 'max_length':64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anil Ambani'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_huggingface.predict('whats is the name of mukesh ambani son?')\n",
    "# if you compare the output of HuggingFace model gave one word output and OPENAI model gave us the detailed output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor\n",
      "\n",
      "\n",
      "Rohit Sharma is an Indian cricketer who is the vice-captain of the Indian national cricket team in limited-overs formats. He is a right-handed batsman and occasional right-arm off break bowler. He made his international debut in 2007 and has since become one of the most successful batsmen in the world, holding several records in limited-overs cricket. He is known for his elegant stroke-play and has scored three double centuries in One Day International (ODI) cricket. Sharma is also the captain of the Mumbai Indians in the Indian Premier League. \n"
     ]
    }
   ],
   "source": [
    "# lets try with some other thing\n",
    "\n",
    "Hugging_output = llm_huggingface.predict('who is rohit sharma?')\n",
    "OpenAI_output = llm.predict('who is rohit sharma?')\n",
    "\n",
    "print(Hugging_output)\n",
    "print(OpenAI_output)\n",
    "# Now we can see the power of open source modles like GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "# Lets make a chain with the use of Prompt Templates\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "template = 'What is the capital of the {country}'\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['country'], template=template)\n",
    "\n",
    "prompt.format(country = 'india')\n",
    "\n",
    "llm=OpenAI(temperature = 0.8,api_key=openai_key)\n",
    "\n",
    "chain = LLMChain(prompt=prompt,llm=llm)\n",
    "\n",
    "print(chain.run('india'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining multiple chains using simple sequential chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'india', 'output': \"\\n\\n1. The Red Fort - This iconic landmark is a must-visit for any tourist in Delhi. It was the residence of Mughal emperors for nearly 200 years and is now a symbol of India's rich history and cultural heritage.\\n\\n2. India Gate - This war memorial is a popular spot for locals and tourists alike. It was built in memory of the soldiers who lost their lives in World War I and is surrounded by beautiful gardens and fountains.\\n\\n3. Qutub Minar - This 73-meter tall tower is the tallest brick minaret in the world. It was built in the early 13th century and is a UNESCO World Heritage Site, attracting visitors with its intricate architecture and historical significance.\\n\\n4. Lotus Temple - Shaped like a lotus flower, this Bahá'í House of Worship is one of the most visited places in Delhi. It is known for its peaceful atmosphere and welcomes people of all religions to pray and meditate.\\n\\n5. Chandni Chowk - This bustling market in Old Delhi is a paradise for shopaholics and foodies. It offers a glimpse into the traditional way of life in Delhi and is known for its narrow streets, vibrant bazaars, and delicious street food.\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "template = 'What is the capital of the {country}'\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['country'], template=template)\n",
    "\n",
    "llm=OpenAI(temperature = 0.8,api_key=openai_key)\n",
    "\n",
    "chain = LLMChain(prompt=prompt,llm=llm,output_key='capital')\n",
    "\n",
    "famouse_template = 'tell me 5 famouse places of that {capital}'\n",
    "\n",
    "famouse_prompt = PromptTemplate(input_variables=['capital'], template=famouse_template)\n",
    "\n",
    "chain2 = LLMChain(prompt=famouse_prompt,llm=llm)\n",
    "\n",
    "combine_chain = SimpleSequentialChain(chains=[chain,chain2])\n",
    "\n",
    "print(combine_chain.invoke('india'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    In the above output we could see that we only got the ouput of last chain and not the earlier chains hence to get ouput of all chains we will use sequential chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'india', 'capital': '\\n\\nThe capital of India is New Delhi.', 'places': \" Here are five famous places in Delhi:\\n\\n1. The Red Fort: This historic fort, built in the 17th century, is a symbol of India's struggle for independence. It is a UNESCO World Heritage Site and a popular tourist attraction.\\n\\n2. Qutub Minar: This 73-meter tall minaret is the tallest brick minaret in the world and is a prime example of Indo-Islamic architecture. It is also a UNESCO World Heritage Site.\\n\\n3. India Gate: This iconic 42-meter tall archway is a war memorial dedicated to the soldiers who died during World War I. It is a popular spot for picnics and evening strolls.\\n\\n4. Lotus Temple: This architectural marvel is a Bahá'í House of Worship, shaped like a lotus flower. It is open to people of all faiths and is known for its serene atmosphere.\\n\\n5. Jama Masjid: This grand mosque, built in the 17th century, is one of the largest and most famous mosques in India. It is a popular place of worship for Muslims and also attracts tourists for its stunning architecture.\"}\n"
     ]
    }
   ],
   "source": [
    "# Sequential Chain\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "template = 'What is the capital of the {country}'\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['country'], template=template)\n",
    "\n",
    "llm=OpenAI(temperature = 0.8,api_key=openai_key)\n",
    "\n",
    "chain = LLMChain(prompt=prompt,llm=llm,output_key='capital')\n",
    "\n",
    "famouse_template = 'tell me 5 famouse places of that {capital}'\n",
    "\n",
    "famouse_prompt = PromptTemplate(input_variables=['capital'], template=famouse_template)\n",
    "\n",
    "chain2 = LLMChain(prompt=famouse_prompt,llm=llm,output_key='places')\n",
    "\n",
    "combine_chain = SequentialChain(chains=[chain,chain2],input_variables=['country'],\n",
    "output_variables=['capital',\"places\"])\n",
    "\n",
    "print(combine_chain.invoke('india'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatmodels With ChatOpenAI\n",
    " it is very useful in creation of conversations chat modles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. Why did the robot go to therapy? It had too many \"byte\" sized issues!\\n2. How does an AI flirt? With binary code: 01101000 01100101 01101100 01101100 01101111\\n3. Why was the AI bad at dating? It kept getting stuck in an infinite loop of self-doubt!\\n4. Why did the robot break up with its calculator girlfriend? It just couldn\\'t find the right \"function\" to make it work!\\n5. What do you call a robot who tells jokes? A stand-up data scientist!', response_metadata={'token_usage': {'completion_tokens': 123, 'prompt_tokens': 26, 'total_tokens': 149}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-399fe5b7-754d-4d87-8ad2-fa0ddd1307a8-0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0.9,model = 'gpt-3.5-turbo',api_key=openai_key)\n",
    "\n",
    "chat_model\n",
    "\n",
    "# SystemMessage = This is the role taht we assin to to the chat model\n",
    "# HumanMessage = This is the request we make to the chat model\n",
    "# AIMessage = This is the reply of the chat model\n",
    "\n",
    "chat_model.invoke([\n",
    "    SystemMessage(content='You are the comedian AI assistant'),\n",
    "    HumanMessage(content='please provide some comedy puch lines on AI')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + LLM + Output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaSeperatedOutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"Your are a helpful assistant. When the user give any input , you should generate 5 words synonyms in a comma seperated list\"\n",
    "human_template=\"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' brilliant', ' ingenious']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With output parser\n",
    "chain=chatprompt|chat_model|CommaSeperatedOutput()\n",
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='smart, clever, bright, sharp, astute', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 39, 'total_tokens': 49}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-484d871d-c4d6-4c7c-82c6-b1c781926af8-0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without output parser\n",
    "chain=chatprompt|chat_model\n",
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
